=======
doc_df = docs
}
>>>>>>> Stashed changes
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
record_df$YEAR = str_extract(record_df$EIS.Number,'^[0-9]{4}')
#record_df = record_df[YEAR %in% 2013:2019,]
fls <- list.files('enepa_repository/documents/',recursive = T)
check_projs <- unique(str_extract(doc_df$File_Name[!doc_df$File_Name %in% basename(fls)],'^[0-9]{8}'))
record_df = record_df[({!EIS.Number %in% doc_df$EIS.Number} | EIS.Number %in% check_projs) & YEAR>2012,]
<<<<<<< Updated upstream
record_df[order(-EIS.Number),]
=======
>>>>>>> Stashed changes
for (i in 1:nrow(record_df)){
Sys.sleep(0.25)
print(record_df$EIS.Number[i])
try = RCurl::getURL(record_df$eis_url[i])
if(!grepl('Server Error',try)){
htmlNodes = record_df$eis_url[i] %>% read_html()  %>% html_nodes('a')
file_url = grep('downloadAttachment',htmlNodes %>% html_attr('href') ,value=T)
file_names = {htmlNodes %>% html_text()}[grepl('downloadAttachment',htmlNodes %>% html_attr('href'))]
file_names = gsub('~|/','-',file_names)
file_names = gsub('\\s{1,}','_',file_names)
file_names = gsub('PDF$','pdf',file_names)
if(length(file_url)==0){next}
for (j in 1:length(file_url)){
subd = str_extract(record_df$EIS.Number[i],'^[0-9]{4}')
if(!dir.exists(paste0(file_storage,subd))){dir.create(paste0(file_storage,subd))}
if(file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(!file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
temp_name = paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_'))
temp_name <- gsub('PDF$','pdf',temp_name)
<<<<<<< Updated upstream
download = tryCatch(httr::GET(paste0(base_page,file_url[j]), verbose(),write_disk(temp_name), overwrite=TRUE),error=function(e) NULL)
temp_info = file.info(temp_name)
if(is.null(download)){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
=======
temp_name <- str_remove_all(temp_name,'\\(|\\)')
download = tryCatch(httr::GET(paste0(base_page,file_url[j]), verbose(),write_disk(temp_name), overwrite=TRUE),error=function(e) NULL)
temp_info = file.info(temp_name)
if(is.null(download)){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
>>>>>>> Stashed changes
}
if(!is.null(download)){
temp_info$size = file.info(temp_name)
if(file.size(temp_name)==0&all(duplicated(file_names))){
<<<<<<< Updated upstream
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
=======
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
>>>>>>> Stashed changes
}
if(file.size(temp_name)==0&file_names[j] %in% file_names[-j]){
file.remove(temp_name)
next
}
if(file.size(temp_name)>0){
<<<<<<< Updated upstream
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
=======
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)'),sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
}
}
doc_df = rbind(doc_df,tdf,use.names = T,fill = T)
}
}
}
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
record_df = fread('enepa_repository/metadata/eis_record_detail.csv',stringsAsFactors = F)
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
docs = fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
current_flist = list.files(file_storage,recursive = T)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
docs = docs[YEAR>=2012,]
doc_df = docs
doc_df$File_Name <- str_remove_all(doc_df$File_Name,'\\&')
flist <- list.files('enepa_repository/documents/',recursive = T,full.names = T)
flist <- grep('\\&',flist,value = T)
flist
file.rename(from = flist,to = str_remove_all(flist,'\\&'))
write.csv(x = doc_df,file = paste0('enepa_repository/metadata/eis_document_record','.csv'),row.names = F)
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
record_df = fread('enepa_repository/metadata/eis_record_detail.csv',stringsAsFactors = F)
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
rerunALL = FALSE
if(!rerunALL){
docs = fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
current_flist = list.files(file_storage,recursive = T)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
docs = docs[YEAR>=2012,]
doc_df = docs
}
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
record_df$YEAR = str_extract(record_df$EIS.Number,'^[0-9]{4}')
#record_df = record_df[YEAR %in% 2013:2019,]
fls <- list.files('enepa_repository/documents/',recursive = T)
check_projs <- unique(str_extract(doc_df$File_Name[!doc_df$File_Name %in% basename(fls)],'^[0-9]{8}'))
record_df = record_df[({!EIS.Number %in% doc_df$EIS.Number} | EIS.Number %in% check_projs) & YEAR>2012,]
for (i in 1:nrow(record_df)){
Sys.sleep(0.25)
print(record_df$EIS.Number[i])
try = RCurl::getURL(record_df$eis_url[i])
if(!grepl('Server Error',try)){
htmlNodes = record_df$eis_url[i] %>% read_html()  %>% html_nodes('a')
file_url = grep('downloadAttachment',htmlNodes %>% html_attr('href') ,value=T)
file_names = {htmlNodes %>% html_text()}[grepl('downloadAttachment',htmlNodes %>% html_attr('href'))]
file_names = gsub('~|/','-',file_names)
file_names = gsub('\\s{1,}','_',file_names)
file_names = gsub('PDF$','pdf',file_names)
if(length(file_url)==0){next}
for (j in 1:length(file_url)){
subd = str_extract(record_df$EIS.Number[i],'^[0-9]{4}')
if(!dir.exists(paste0(file_storage,subd))){dir.create(paste0(file_storage,subd))}
if(file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(!file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
temp_name = paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_'))
temp_name <- gsub('PDF$','pdf',temp_name)
temp_name <- str_remove_all(temp_name,'\\(|\\)\\&')
download = tryCatch(httr::GET(paste0(base_page,file_url[j]), verbose(),write_disk(temp_name), overwrite=TRUE),error=function(e) NULL)
temp_info = file.info(temp_name)
if(is.null(download)){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)\\&'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(!is.null(download)){
temp_info$size = file.info(temp_name)
if(file.size(temp_name)==0&all(duplicated(file_names))){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)\\&'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(file.size(temp_name)==0&file_names[j] %in% file_names[-j]){
file.remove(temp_name)
next
}
if(file.size(temp_name)>0){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)\\&'),sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
}
}
doc_df = rbind(doc_df,tdf,use.names = T,fill = T)
}
}
}
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
record_df = fread('enepa_repository/metadata/eis_record_detail.csv',stringsAsFactors = F)
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
head(record_df)
rerunALL = FALSE
if(!rerunALL){
docs = fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
current_flist = list.files(file_storage,recursive = T)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
docs = docs[YEAR>=2012,]
doc_df = docs
}
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
record_df$YEAR = str_extract(record_df$EIS.Number,'^[0-9]{4}')
fls <- list.files('enepa_repository/documents/',recursive = T)
check_projs <- unique(str_extract(doc_df$File_Name[!doc_df$File_Name %in% basename(fls)],'^[0-9]{8}'))
record_df = record_df[({!EIS.Number %in% doc_df$EIS.Number} | EIS.Number %in% check_projs) & YEAR>2012,]
record_df
check_projs
check_projs
doc_df[doc_df$EIS.Number%in%check_projs,]
doc_df[doc_df$EIS.Number%in%check_projs,]$File_Name
doc_df[doc_df$EIS.Number%in%check_projs,]$File_Name
grep('\\,',fls,value = T)
fls_temp <- grep('\\,',fls,value = T)
file.rename(fls_temp,str_remove_all(fls_temp,"\\,"))
warnings()
fls_temp <- list.files('enepa_repository/documents/',recursive = T,full.names = T)
fls_temp <- grep('\\,',fls,value = T)
file.rename(fls_temp,str_remove_all(fls_temp,"\\,"))
fls_temp <- list.files('enepa_repository/documents/',recursive = T,full.names = T)
fls_temp <- grep('\\,',fls_temp,value = T)
file.rename(fls_temp,str_remove_all(fls_temp,"\\,"))
docs = fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
current_flist = list.files(file_storage,recursive = T)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
docs = docs[YEAR>=2012,]
doc_df = docs
doc_df$File_Name
grep('\\,',doc_df$File_Name,value = T)
str_remove_all(doc_df$File_Name,"\\,")
doc_df$File_Name <- str_remove_all(doc_df$File_Name,"\\,")
write.csv(x = doc_df,file = paste0('enepa_repository/metadata/eis_document_record','.csv'),row.names = F)
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
record_df = fread('enepa_repository/metadata/eis_record_detail.csv',stringsAsFactors = F)
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
rerunALL = FALSE
if(!rerunALL){
docs = fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
current_flist = list.files(file_storage,recursive = T)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
docs = docs[YEAR>=2012,]
doc_df = docs
}
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
record_df$YEAR = str_extract(record_df$EIS.Number,'^[0-9]{4}')
#record_df = record_df[YEAR %in% 2013:2019,]
fls <- list.files('enepa_repository/documents/',recursive = T)
check_projs <- unique(str_extract(doc_df$File_Name[!doc_df$File_Name %in% basename(fls)],'^[0-9]{8}'))
record_df = record_df[({!EIS.Number %in% doc_df$EIS.Number} | EIS.Number %in% check_projs) & YEAR>2012,]
for (i in 1:nrow(record_df)){
Sys.sleep(0.25)
print(record_df$EIS.Number[i])
try = RCurl::getURL(record_df$eis_url[i])
if(!grepl('Server Error',try)){
htmlNodes = record_df$eis_url[i] %>% read_html()  %>% html_nodes('a')
file_url = grep('downloadAttachment',htmlNodes %>% html_attr('href') ,value=T)
file_names = {htmlNodes %>% html_text()}[grepl('downloadAttachment',htmlNodes %>% html_attr('href'))]
file_names = gsub('~|/','-',file_names)
file_names = gsub('\\s{1,}','_',file_names)
file_names = gsub('PDF$','pdf',file_names)
if(length(file_url)==0){next}
for (j in 1:length(file_url)){
subd = str_extract(record_df$EIS.Number[i],'^[0-9]{4}')
if(!dir.exists(paste0(file_storage,subd))){dir.create(paste0(file_storage,subd))}
if(file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],file_names[j],sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(!file.exists(paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_')))){
temp_name = paste0(file_storage,subd,'/',paste(record_df$EIS.Number[i],file_names[j],sep='_'))
temp_name <- gsub('PDF$','pdf',temp_name)
temp_name <- str_remove_all(temp_name,'\\(|\\)|\\&|\\,')
download = tryCatch(httr::GET(paste0(base_page,file_url[j]), verbose(),write_disk(temp_name), overwrite=TRUE),error=function(e) NULL)
temp_info = file.info(temp_name)
if(is.null(download)){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)|\\&|\\,'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(!is.null(download)){
temp_info$size = file.info(temp_name)
if(file.size(temp_name)==0&all(duplicated(file_names))){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)|\\&|\\,'),sep='_'),BAD_FILE=T,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
if(file.size(temp_name)==0&file_names[j] %in% file_names[-j]){
file.remove(temp_name)
next
}
if(file.size(temp_name)>0){
tdf = data.frame(EIS.Number = record_df$EIS.Number[i],Original_File_Name = file_names[j],File_Name = paste(record_df$EIS.Number[i],str_remove_all(file_names[j],'\\(|\\)|\\&|\\,'),sep='_'),BAD_FILE=F,PDF = grepl('PDF$',toupper(file_names[j])),stringsAsFactors = F)
}
>>>>>>> Stashed changes
}
}
doc_df = rbind(doc_df,tdf,use.names = T,fill = T)
}
}
}
write.csv(x = doc_df,file = paste0('enepa_repository/metadata/eis_document_record','.csv'),row.names = F)
<<<<<<< Updated upstream
if(!require(data.table)){install.packages('data.table');require(data.table)}
if(!require(stringr)){install.packages('stringr');require(stringr)}
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
if(!require(doParallel)){install.packages('doParallel');require(doParallel)}
if(!require(pdftools)){install.packages('pdftools');require(pdftools)}
if(!require(textclean)){install.packages('textclean');require(pdftools)}
projects = fread('enepa_repository/meta_data/eis_record_detail.csv',colClasses = 'character')
install.packages('textclean')
install.packages("textclean")
if(!require(data.table)){install.packages('data.table');require(data.table)}
if(!require(stringr)){install.packages('stringr');require(stringr)}
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
if(!require(doParallel)){install.packages('doParallel');require(doParallel)}
if(!require(pdftools)){install.packages('pdftools');require(pdftools)}
if(!require(textclean)){install.packages('textclean');require(pdftools)}
if(!require(textclean)){install.packages('textclean');require(textclean)}
projects = fread('enepa_repository/meta_data/eis_record_detail.csv',colClasses = 'character')
projects = fread('enepa_repository/metadata/eis_record_detail.csv',colClasses = 'character')
documents = fread('enepa_repository/metadata/eis_document_record.csv',colClasses = 'character')
pdf_files = list.files('enepa_repository/documents/',full.names = T,recursive = T)
txt_files = list.files('enepa_repository/text_as_datatable/',full.names = T,recursive = T)
still_need = documents[!gsub('pdf$','txt',documents$File_Name) %in% basename(txt_files),]
dr <- list.dirs('enepa_repository/documents')
dr2 <- gsub('documents','text_as_datatable',dr)
sapply(dr2[!dir.exists(dr2)],dir.create)
for(i in nrow(still_need):1){
pdf_name = grep(still_need$File_Name[i],pdf_files,value = T)
print(pdf_name)
text_name = gsub('enepa_repository/documents','enepa_repository/text_as_datatable',pdf_name,fixed = T)
text_name <- gsub('pdf$','txt',text_name)
temp_text = tryCatch({pdftools::pdf_text(grep(still_need$File_Name[i],pdf_files,value = T))},error = function(e) NULL)
if(!is.null(temp_text) & length(temp_text)>0 & any(temp_text!='')){
temp_page = unlist(sapply(temp_text,function(x) x))
temp_page = gsub('\\s{1,}',' ',temp_page)
temp = data.table::data.table(Page = seq_along(temp_page),text = temp_page,stringsAsFactors = F)
temp$text[nchar(temp$text)>10000] <- ''
#temp = temp[!grepl('\\.{10,}',temp$text),]
temp$text = textclean::replace_non_ascii(temp$text)
#temp = temp[!grepl('^Figure [0-9]',temp$text),]
temp$text = gsub('\\s{1,}$','',temp$text)
#temp = temp[nchar(temp$text)>500,]
temp = temp[!duplicated(text)&text!='',]
if(nrow(temp)>0){
fwrite(x = temp,file = text_name,sep = '\t')
}
}
}
fname = 'enepa_repository/metadata/eis_record_detail.csv'
temp <- fread(fname)
library(data.table)
temp <- fread(fname)
saveRDS(temp,'enepa_repository/metadata/eis_record_detail.rds')
=======
#
>>>>>>> Stashed changes
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
rerunALL = T
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
doc_file_name <- 'enepa_repository/metadata/eis_document_record.rds'
record_df = readRDS('enepa_repository/metadata/eis_record_detail.rds')
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
record_df$YEAR <- str_extract(record_df$EIS.Number,'^[0-9]{4}')
current_flist = list.files(file_storage,recursive = T,pattern = 'pdf')
if(!rerunALL){
docs = readRDS(doc_file_name)#fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
#docs = docs[YEAR>=2012,]
doc_df = docs
}
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
not_empty
fino
!rerunALL
current_flist = list.files(file_storage,recursive = T,pattern = 'pdf')
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
current_flist
library(rvest)
library(stringr)
library(tidyverse)
library(httr)
library(data.table)
rerunALL = T
packs = c('rvest','stringr','tidyverse','httr','data.table','RCurl')
sapply(packs[!packs %in% installed.packages()[,'Package']],install.packages)
sapply(packs,require,character.only = T)
file_storage = 'enepa_repository/documents/'
doc_file_name <- 'enepa_repository/metadata/eis_document_record.rds'
record_df = readRDS('enepa_repository/metadata/eis_record_detail.rds')
record_df = record_df %>% mutate_if(is.logical,as.character)
record_df = data.table(record_df)
record_df = record_df[order(-EIS.Number)]
record_df$YEAR <- str_extract(record_df$EIS.Number,'^[0-9]{4}')
current_flist = list.files(file_storage,recursive = T,pattern = 'pdf')
if(!rerunALL){
docs = readRDS(doc_file_name)#fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
docs$YEAR = str_extract(docs$EIS.Number,'^[0-9]{4}')
#docs = docs[YEAR>=2012,]
doc_df = docs
}
if(rerunALL){
#needed_docs = docs[!paste(docs$YEAR,docs$File_Name,sep = '/') %in% current_flist,]
doc_df = data.table(EIS.Number = as.numeric(),Original_File_Name = as.character(),
File_Name =as.character(),BAD_FILE =  logical(),PDF = logical(),stringsAsFactors = F)
}
base_page = 'https://cdxapps.epa.gov'
finfo = file.info(paste0(file_storage,current_flist))
not_empty = finfo$size>0
not_empty
if(any(!not_empty)){
file.remove(paste0(file_storage,current_flist[!not_empty]))
current_flist = current_flist[not_empty]
}
fls <- list.files('enepa_repository/documents/',recursive = T)
check_projs <- unique(str_extract(doc_df$File_Name[!doc_df$File_Name %in% basename(fls)],'^[0-9]{8}'))
record_df = record_df[({!EIS.Number %in% doc_df$EIS.Number} | EIS.Number %in% check_projs) & YEAR>2012,]
i = 100
print(record_df$EIS.Number[i])
try = RCurl::getURL(record_df$eis_url[i])
htmlNodes = record_df$eis_url[i] %>% read_html()
htmlNodes %>% html_nodes('a')
htmlNodes %>% html_nodes('a:contains("download")')
htmlNodes %>% html_nodes('a') %>% html_attr('href')
rvest::html_text2( htmlNodes )
txt <- rvest::html_text2( htmlNodes )
str_extract_all(txt,'Comment\\sLetter.*')
record_df$eis_url[i]
str_extract(txt,'Comment\\sLetter.*')
str_extract(txt,'Comment\\sLetter.+')
str_extract(txt,'Comment\\sLetter\\(s\\).+')
str_remove(txt,'^.+(?:Comment\\sLetter\\(s\\))')
str_remove(txt,'^.+(?=Comment\\sLetter\\(s\\))')
str_remove(txt,'^.+(?!Comment\\sLetter\\(s\\))')
doc <- read_lines(record_df$eis_url[i])
doc
grep('Comment\\sLetter\\(s\\)',doc)
grep('Comment\\sLetter\\(s\\)',doc):length(doc)
doc[grep('Comment\\sLetter\\(s\\)',doc):length(doc)]
doc[grep('Comment\\sLetter\\(s\\)',doc):length(doc)] %>% html_nodes('a')
doc <- doc[grep('Comment\\sLetter\\(s\\)',doc):length(doc)]
doc[grepl('pdf$',doc)]
doc[grepl('\\.pdf',doc)]
library(textutils)
install.packages('textutils')
library(textutils)
toHTML(doc)
grep('Calcasieu',doc_df$File_Name)
docs = readRDS(doc_file_name)#fread('enepa_repository/metadata/eis_document_record.csv',stringsAsFactors = F)
((doc_file_name)
doc_file_name
